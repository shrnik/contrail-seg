{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPn1JLEHJwTq",
        "outputId": "9669ba0e-5cd3-4c65-9f24-bf9851bef2e6"
      },
      "id": "XPn1JLEHJwTq",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.23.0)\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.235-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.12.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.46.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.235-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.235 ultralytics-thop-2.0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2103a4da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2103a4da",
        "outputId": "4107a85b-607c-4fa3-bce9-243a94cd7bc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "import wandb\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a4df7599",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4df7599",
        "outputId": "b62d7e01-9e53-46a5-a074-e50005ee1f31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Login to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "24533a44",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24533a44",
        "outputId": "3c50ebac-cdd0-4fe3-d169-a39e8deec482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshrenikborad\u001b[0m (\u001b[33mshrenikborad-the-george-washington-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "587f8c2b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "587f8c2b",
        "outputId": "d1d3568e-708e-4b12-aebd-cfc6bfa75af3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Updated 'wandb=True'\n",
            "JSONDict(\"/root/.config/Ultralytics/settings.json\"):\n",
            "{\n",
            "  \"settings_version\": \"0.0.6\",\n",
            "  \"datasets_dir\": \"/content/datasets\",\n",
            "  \"weights_dir\": \"weights\",\n",
            "  \"runs_dir\": \"runs\",\n",
            "  \"uuid\": \"569f3ba64b326db489132663f79cd37279811de477381b83ac131e6cdd129cbb\",\n",
            "  \"sync\": true,\n",
            "  \"api_key\": \"\",\n",
            "  \"openai_api_key\": \"\",\n",
            "  \"clearml\": true,\n",
            "  \"comet\": true,\n",
            "  \"dvc\": true,\n",
            "  \"hub\": true,\n",
            "  \"mlflow\": true,\n",
            "  \"neptune\": true,\n",
            "  \"raytune\": true,\n",
            "  \"tensorboard\": false,\n",
            "  \"wandb\": true,\n",
            "  \"vscode_msg\": true,\n",
            "  \"openvino_msg\": true\n",
            "}\n",
            "ğŸ’¡ Learn more about Ultralytics Settings at https://docs.ultralytics.com/quickstart/#ultralytics-settings\n"
          ]
        }
      ],
      "source": [
        "!yolo settings wandb=True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"/content/drive/MyDrive/contrails_swg/data\""
      ],
      "metadata": {
        "id": "tlRAtg7XlTH5"
      },
      "id": "tlRAtg7XlTH5",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "def convert_coco_to_yolo(json_path, source_img_dir, output_dir, val_split=0.2):\n",
        "    with open(json_path, 'r') as f:\n",
        "        coco = json.load(f)\n",
        "\n",
        "    # Create directories\n",
        "    output_dir = Path(output_dir)\n",
        "    (output_dir / 'images' / 'train').mkdir(parents=True, exist_ok=True)\n",
        "    (output_dir / 'images' / 'val').mkdir(parents=True, exist_ok=True)\n",
        "    (output_dir / 'labels' / 'train').mkdir(parents=True, exist_ok=True)\n",
        "    (output_dir / 'labels' / 'val').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Map categories to indices (0-indexed)\n",
        "    # Ensure consistent ordering\n",
        "    categories = sorted(coco['categories'], key=lambda x: x['id'])\n",
        "    cat_id_to_idx = {cat['id']: i for i, cat in enumerate(categories)}\n",
        "    cat_names = [cat['name'] for cat in categories]\n",
        "\n",
        "    print(f\"Categories mapping: {cat_id_to_idx}\")\n",
        "    print(f\"Category names: {cat_names}\")\n",
        "\n",
        "    # Group annotations by image\n",
        "    img_to_anns = {}\n",
        "    for ann in coco['annotations']:\n",
        "        img_id = ann['image_id']\n",
        "        if img_id not in img_to_anns:\n",
        "            img_to_anns[img_id] = []\n",
        "        img_to_anns[img_id].append(ann)\n",
        "\n",
        "    # Split images\n",
        "    images = coco['images']\n",
        "    random.shuffle(images)\n",
        "    split_idx = int(len(images) * (1 - val_split))\n",
        "    train_images = images[:split_idx]\n",
        "    val_images = images[split_idx:]\n",
        "\n",
        "    def process_images(image_list, split_name):\n",
        "        for img_info in tqdm(image_list, desc=f\"Processing {split_name}\"):\n",
        "            img_id = img_info['id']\n",
        "            file_name = img_info['file_name']\n",
        "            width = img_info['width']\n",
        "            height = img_info['height']\n",
        "\n",
        "            # Copy image\n",
        "            src_path = Path(source_img_dir) / file_name\n",
        "            if not src_path.exists():\n",
        "                # Try adding underscore after 8th char (date)\n",
        "                if len(file_name) > 8 and file_name[8] != '_':\n",
        "                    alt_name = file_name[:8] + '_' + file_name[8:]\n",
        "                    src_path_alt = Path(source_img_dir) / alt_name\n",
        "                    if src_path_alt.exists():\n",
        "                        src_path = src_path_alt\n",
        "                        # print(f\"Fixed filename: {file_name} -> {alt_name}\")\n",
        "\n",
        "            dst_path = output_dir / 'images' / split_name / file_name # Keep original name in dest or use fixed?\n",
        "            # Better to use the fixed name in dest so it matches the label file which is derived from file_name\n",
        "            # But wait, the label file is derived from file_name (from JSON).\n",
        "            # If I change the image name on disk, I should also change the label filename.\n",
        "            # Let's use the found src filename as the basis for dest filename to ensure consistency.\n",
        "\n",
        "            if src_path.exists():\n",
        "                dst_path = output_dir / 'images' / split_name / src_path.name\n",
        "                shutil.copy(src_path, dst_path)\n",
        "                # Update file_name to match the one on disk for label generation\n",
        "                file_name = src_path.name\n",
        "            else:\n",
        "                print(f\"Warning: Image {file_name} not found (tried {src_path}).\")\n",
        "                continue\n",
        "\n",
        "            # Create label file\n",
        "            label_path = output_dir / 'labels' / split_name / f\"{Path(file_name).stem}.txt\"\n",
        "\n",
        "            anns = img_to_anns.get(img_id, [])\n",
        "            with open(label_path, 'w') as f:\n",
        "                for ann in anns:\n",
        "                    if 'segmentation' not in ann:\n",
        "                        continue\n",
        "\n",
        "                    cat_idx = cat_id_to_idx[ann['category_id']]\n",
        "\n",
        "                    for seg in ann['segmentation']:\n",
        "                        # seg is a list of coordinates [x1, y1, x2, y2, ...]\n",
        "                        # Normalize\n",
        "                        points = np.array(seg).reshape(-1, 2).astype(float)\n",
        "                        points[:, 0] /= width\n",
        "                        points[:, 1] /= height\n",
        "\n",
        "                        # Clip to [0, 1] just in case\n",
        "                        points = np.clip(points, 0, 1)\n",
        "\n",
        "                        # Format: class x1 y1 x2 y2 ...\n",
        "                        line = f\"{cat_idx} \" + \" \".join([f\"{x:.6f} {y:.6f}\" for x, y in points])\n",
        "                        f.write(line + \"\\n\")\n",
        "\n",
        "    process_images(train_images, 'train')\n",
        "    process_images(val_images, 'val')\n",
        "\n",
        "    # Create data.yaml\n",
        "    yaml_content = f\"\"\"\n",
        "path: {output_dir.absolute()}\n",
        "train: images/train\n",
        "val: images/val\n",
        "names:\n",
        "\"\"\"\n",
        "    for idx, name in enumerate(cat_names):\n",
        "        yaml_content += f\"  {idx}: {name}\\n\"\n",
        "\n",
        "    with open(output_dir / 'data.yaml', 'w') as f:\n",
        "        f.write(yaml_content)\n",
        "\n",
        "    print(f\"Dataset prepared at {output_dir}\")\n",
        "    print(f\"data.yaml created at {output_dir / 'data.yaml'}\")\n",
        "\n",
        "convert_coco_to_yolo(\n",
        "    json_path=f'{DATA_DIR}/annotations.coco.json',\n",
        "    source_img_dir=DATA_DIR,\n",
        "    output_dir='datasets/contrail-seg'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0nH5qVflAp8",
        "outputId": "4b37a9eb-6129-43df-881c-71bb1adcbb3e"
      },
      "id": "M0nH5qVflAp8",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categories mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}\n",
            "Category names: ['contrail', 'contrail maybe', 'contrail old', 'contrail veryold', 'contrail young', 'parasite', 'sun', 'unknow']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1280/1280 [04:52<00:00,  4.37it/s]\n",
            "Processing val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 320/320 [01:10<00:00,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset prepared at datasets/contrail-seg\n",
            "data.yaml created at datasets/contrail-seg/data.yaml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89e6dea4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "89e6dea4",
        "outputId": "4030aba5-35e1-4bc2-b5cf-55ccd7ee9936"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251206_010146-ezqhzj1x</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shrenikborad-the-george-washington-university/contrails-seg/runs/ezqhzj1x' target=\"_blank\">rosy-sea-20</a></strong> to <a href='https://wandb.ai/shrenikborad-the-george-washington-university/contrails-seg' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/shrenikborad-the-george-washington-university/contrails-seg' target=\"_blank\">https://wandb.ai/shrenikborad-the-george-washington-university/contrails-seg</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/shrenikborad-the-george-washington-university/contrails-seg/runs/ezqhzj1x' target=\"_blank\">https://wandb.ai/shrenikborad-the-george-washington-university/contrails-seg/runs/ezqhzj1x</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x-seg.pt to 'yolo11x-seg.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 119.3MB 134.3MB/s 0.9s\n",
            "Ultralytics 8.3.235 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/datasets/contrail-seg/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11x-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=contrail-segmentation-runL, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/contrails_seg/train2, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/contrails_seg/train2/contrail-segmentation-runL, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 14.1MB/s 0.1s\n",
            "Overriding model.yaml nc=80 with nc=8\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      2784  ultralytics.nn.modules.conv.Conv             [3, 96, 3, 2]                 \n",
            "  1                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  2                  -1  2    389760  ultralytics.nn.modules.block.C3k2            [192, 384, 2, True, 0.25]     \n",
            "  3                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            "  4                  -1  2   1553664  ultralytics.nn.modules.block.C3k2            [384, 768, 2, True, 0.25]     \n",
            "  5                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
            "  6                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
            "  7                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
            "  8                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
            "  9                  -1  1   1476864  ultralytics.nn.modules.block.SPPF            [768, 768, 5]                 \n",
            " 10                  -1  2   3264768  ultralytics.nn.modules.block.C2PSA           [768, 768, 2]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  2   1700352  ultralytics.nn.modules.block.C3k2            [1536, 384, 2, True]          \n",
            " 17                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  2   5317632  ultralytics.nn.modules.block.C3k2            [1152, 768, 2, True]          \n",
            " 20                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n",
            " 23        [16, 19, 22]  1   8331272  ultralytics.nn.modules.head.Segment          [8, 32, 384, [384, 768, 768]] \n",
            "YOLO11x-seg summary: 379 layers, 62,059,496 parameters, 62,059,480 gradients, 297.1 GFLOPs\n",
            "\n",
            "Transferred 1071/1077 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 65.9MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 996.5Â±343.5 MB/s, size: 35.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/contrail-seg/labels/train... 1280 images, 268 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1280/1280 1.5Kit/s 0.9s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/contrail-seg/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA A100-SXM4-40GB) 39.56G total, 0.54G reserved, 0.51G allocated, 38.51G free\n",
            "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
            "    62059496       297.1         4.144         109.8           nan        (1, 3, 640, 640)                    list\n",
            "    62059496       594.1         7.835         66.27           nan        (2, 3, 640, 640)                    list\n",
            "    62059496        1188        12.992         71.05           nan        (4, 3, 640, 640)                    list\n",
            "    62059496        2377        23.863         82.37           nan        (8, 3, 640, 640)                    list\n",
            "    62059496        4753        44.623         107.4           nan       (16, 3, 640, 640)                    list\n",
            "CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 26.88 MiB is free. Process 42235 has 39.52 GiB memory in use. Of the allocated memory 38.70 GiB is allocated by PyTorch, and 304.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 54.88 MiB is free. Process 42235 has 39.49 GiB memory in use. Of the allocated memory 38.55 GiB is allocated by PyTorch, and 424.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 7 for CUDA:0 22.25G/39.56G (56%) âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1286.8Â±501.9 MB/s, size: 36.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/contrail-seg/labels/train.cache... 1280 images, 268 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1280/1280 1.0Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 610.9Â±274.9 MB/s, size: 38.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/contrail-seg/labels/val... 320 images, 59 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 1.2Kit/s 0.3s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/contrail-seg/labels/val.cache\n",
            "Plotting labels to /content/drive/MyDrive/contrails_seg/train2/contrail-segmentation-runL/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 176 weight(decay=0.0), 187 weight(decay=0.0004921875), 186 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/contrails_seg/train2/contrail-segmentation-runL\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/100      8.51G      2.078      2.897      3.341      2.053         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 183/183 3.3it/s 55.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 2.5it/s 9.3s\n",
            "                   all        320        822      0.231      0.224      0.116     0.0401      0.207      0.148     0.0992     0.0324\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/100      9.79G      2.169      2.734      2.873      2.127         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 183/183 5.4it/s 33.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 6.0it/s 3.8s\n",
            "                   all        320        822      0.235      0.193     0.0722     0.0246      0.235      0.131     0.0698     0.0232\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/100      9.87G       2.14      2.714       2.88       2.12         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 183/183 5.5it/s 33.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 5.9it/s 3.9s\n",
            "                   all        320        822      0.166      0.118     0.0111    0.00433      0.165     0.0575     0.0108    0.00333\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/100        10G      2.122      2.659      2.752      2.135         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 183/183 5.5it/s 33.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 6.0it/s 3.8s\n",
            "                   all        320        822      0.505      0.226      0.172     0.0635      0.499      0.192      0.163     0.0535\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/100      10.1G      2.092      2.666       2.68      2.132         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 183/183 5.5it/s 33.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 6.0it/s 3.8s\n",
            "                   all        320        822      0.303       0.17      0.116     0.0406      0.302      0.151      0.105     0.0323\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/100      10.3G      1.972      2.456      2.488      2.058         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 183/183 5.5it/s 33.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 6.0it/s 3.8s\n",
            "                   all        320        822      0.512       0.22      0.189     0.0803      0.495      0.194      0.166     0.0572\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/100      10.8G      1.947      2.469      2.431      2.046         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 183/183 5.5it/s 33.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 6.1it/s 3.8s\n",
            "                   all        320        822      0.517      0.251      0.222     0.0948      0.512      0.221      0.189     0.0701\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/100        11G      1.882      2.354      2.326      1.976         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 183/183 5.5it/s 33.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 23/23 5.7it/s 4.0s\n",
            "                   all        320        822      0.397       0.23      0.214      0.091      0.404      0.231      0.212     0.0789\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/100      11.1G      1.816      2.289        2.3      1.935         25        640: 89% â”â”â”â”â”â”â”â”â”â”â•¸â”€ 162/183 5.5it/s 29.2s<3.8s"
          ]
        }
      ],
      "source": [
        "with wandb.init(project=\"contrails-seg\") as run:\n",
        "    def on_train_epoch_end(trainer):\n",
        "        \"\"\"Callback that runs at the end of each training epoch.\"\"\"\n",
        "        metrics = trainer.metrics\n",
        "        epoch = trainer.epoch\n",
        "\n",
        "        # Log training metrics\n",
        "        log_dict = {\n",
        "            \"epoch\": epoch,\n",
        "        }\n",
        "\n",
        "        # Add box loss metrics\n",
        "        if \"train/box_loss\" in metrics:\n",
        "            log_dict[\"train/box_loss\"] = metrics[\"train/box_loss\"]\n",
        "        if \"train/seg_loss\" in metrics:\n",
        "            log_dict[\"train/seg_loss\"] = metrics[\"train/seg_loss\"]\n",
        "        if \"train/cls_loss\" in metrics:\n",
        "            log_dict[\"train/cls_loss\"] = metrics[\"train/cls_loss\"]\n",
        "        if \"train/dfl_loss\" in metrics:\n",
        "            log_dict[\"train/dfl_loss\"] = metrics[\"train/dfl_loss\"]\n",
        "\n",
        "        # Add validation metrics if available\n",
        "        if \"metrics/precision(M)\" in metrics:\n",
        "            log_dict[\"val/precision\"] = metrics[\"metrics/precision(M)\"]\n",
        "        if \"metrics/recall(M)\" in metrics:\n",
        "            log_dict[\"val/recall\"] = metrics[\"metrics/recall(M)\"]\n",
        "        if \"metrics/mAP50(M)\" in metrics:\n",
        "            log_dict[\"val/mAP50\"] = metrics[\"metrics/mAP50(M)\"]\n",
        "        if \"metrics/mAP50-95(M)\" in metrics:\n",
        "            log_dict[\"val/mAP50-95\"] = metrics[\"metrics/mAP50-95(M)\"]\n",
        "\n",
        "        # Log to W&B\n",
        "        run.log(metrics)\n",
        "    def on_val_end(trainer):\n",
        "        \"\"\"Callback that runs at the end of validation.\"\"\"\n",
        "        metrics = trainer.metrics\n",
        "\n",
        "        # Additional validation metrics can be logged here\n",
        "        val_log_dict = {}\n",
        "\n",
        "        if hasattr(metrics, 'box'):\n",
        "            if hasattr(metrics.box, 'map'):\n",
        "                val_log_dict[\"val/box_mAP\"] = metrics.box.map\n",
        "            if hasattr(metrics.box, 'map50'):\n",
        "                val_log_dict[\"val/box_mAP50\"] = metrics.box.map50\n",
        "\n",
        "        if hasattr(metrics, 'seg'):\n",
        "            if hasattr(metrics.seg, 'map'):\n",
        "                val_log_dict[\"val/seg_mAP\"] = metrics.seg.map\n",
        "            if hasattr(metrics.seg, 'map50'):\n",
        "                val_log_dict[\"val/seg_mAP50\"] = metrics.seg.map50\n",
        "\n",
        "        if val_log_dict:\n",
        "            run.log(val_log_dict)\n",
        "    model = YOLO(\"yolo11x-seg.pt\")\n",
        "    model.add_callback(\"on_train_epoch_end\", on_train_epoch_end)\n",
        "    model.add_callback(\"on_val_end\", on_val_end)\n",
        "    model.train(\n",
        "        data=f\"/content/datasets/contrail-seg/data.yaml\",\n",
        "        epochs=100,\n",
        "        imgsz=640,\n",
        "        name=\"contrail-segmentation-runL\",\n",
        "        exist_ok=True,\n",
        "        batch=-1,\n",
        "        save_period=5,\n",
        "        project=\"/content/drive/MyDrive/contrails_seg/xl\",\n",
        "\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r6kO_I02mkyN"
      },
      "id": "r6kO_I02mkyN",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}