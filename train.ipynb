{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "190971f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "190971f1",
        "outputId": "7651f3b3-270e-465a-d23f-5511d2e2c452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.23.0)\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.235-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.12.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.46.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.235-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.235 ultralytics-thop-2.0.18\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2103a4da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2103a4da",
        "outputId": "7c186a62-1772-475d-9193-8e63a7592b7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "import wandb\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a4df7599",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4df7599",
        "outputId": "3571cf33-e1a1-4193-d2a0-087eb1190053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Login to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "24533a44",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24533a44",
        "outputId": "ae6e9618-fac1-46f0-c332-ba4229bf10b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "587f8c2b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "587f8c2b",
        "outputId": "a40460fb-adab-4e12-db16-4f3ca7915909"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Updated 'wandb=True'\n",
            "JSONDict(\"/root/.config/Ultralytics/settings.json\"):\n",
            "{\n",
            "  \"settings_version\": \"0.0.6\",\n",
            "  \"datasets_dir\": \"/content/datasets\",\n",
            "  \"weights_dir\": \"weights\",\n",
            "  \"runs_dir\": \"runs\",\n",
            "  \"uuid\": \"569f3ba64b326db489132663f79cd37279811de477381b83ac131e6cdd129cbb\",\n",
            "  \"sync\": true,\n",
            "  \"api_key\": \"\",\n",
            "  \"openai_api_key\": \"\",\n",
            "  \"clearml\": true,\n",
            "  \"comet\": true,\n",
            "  \"dvc\": true,\n",
            "  \"hub\": true,\n",
            "  \"mlflow\": true,\n",
            "  \"neptune\": true,\n",
            "  \"raytune\": true,\n",
            "  \"tensorboard\": false,\n",
            "  \"wandb\": true,\n",
            "  \"vscode_msg\": true,\n",
            "  \"openvino_msg\": true\n",
            "}\n",
            "ðŸ’¡ Learn more about Ultralytics Settings at https://docs.ultralytics.com/quickstart/#ultralytics-settings\n"
          ]
        }
      ],
      "source": [
        "!yolo settings wandb=True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"/content/drive/MyDrive/contrails_swg/data\""
      ],
      "metadata": {
        "id": "tlRAtg7XlTH5"
      },
      "id": "tlRAtg7XlTH5",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "def convert_coco_to_yolo(json_path, source_img_dir, output_dir, val_split=0.2):\n",
        "    with open(json_path, 'r') as f:\n",
        "        coco = json.load(f)\n",
        "\n",
        "    # Create directories\n",
        "    output_dir = Path(output_dir)\n",
        "    (output_dir / 'images' / 'train').mkdir(parents=True, exist_ok=True)\n",
        "    (output_dir / 'images' / 'val').mkdir(parents=True, exist_ok=True)\n",
        "    (output_dir / 'labels' / 'train').mkdir(parents=True, exist_ok=True)\n",
        "    (output_dir / 'labels' / 'val').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Map categories to indices (0-indexed)\n",
        "    # Ensure consistent ordering\n",
        "    categories = sorted(coco['categories'], key=lambda x: x['id'])\n",
        "    cat_id_to_idx = {cat['id']: i for i, cat in enumerate(categories)}\n",
        "    cat_names = [cat['name'] for cat in categories]\n",
        "\n",
        "    print(f\"Categories mapping: {cat_id_to_idx}\")\n",
        "    print(f\"Category names: {cat_names}\")\n",
        "\n",
        "    # Group annotations by image\n",
        "    img_to_anns = {}\n",
        "    for ann in coco['annotations']:\n",
        "        img_id = ann['image_id']\n",
        "        if img_id not in img_to_anns:\n",
        "            img_to_anns[img_id] = []\n",
        "        img_to_anns[img_id].append(ann)\n",
        "\n",
        "    # Split images\n",
        "    images = coco['images']\n",
        "    random.shuffle(images)\n",
        "    split_idx = int(len(images) * (1 - val_split))\n",
        "    train_images = images[:split_idx]\n",
        "    val_images = images[split_idx:]\n",
        "\n",
        "    def process_images(image_list, split_name):\n",
        "        for img_info in tqdm(image_list, desc=f\"Processing {split_name}\"):\n",
        "            img_id = img_info['id']\n",
        "            file_name = img_info['file_name']\n",
        "            width = img_info['width']\n",
        "            height = img_info['height']\n",
        "\n",
        "            # Copy image\n",
        "            src_path = Path(source_img_dir) / file_name\n",
        "            if not src_path.exists():\n",
        "                # Try adding underscore after 8th char (date)\n",
        "                if len(file_name) > 8 and file_name[8] != '_':\n",
        "                    alt_name = file_name[:8] + '_' + file_name[8:]\n",
        "                    src_path_alt = Path(source_img_dir) / alt_name\n",
        "                    if src_path_alt.exists():\n",
        "                        src_path = src_path_alt\n",
        "                        # print(f\"Fixed filename: {file_name} -> {alt_name}\")\n",
        "\n",
        "            dst_path = output_dir / 'images' / split_name / file_name # Keep original name in dest or use fixed?\n",
        "            # Better to use the fixed name in dest so it matches the label file which is derived from file_name\n",
        "            # But wait, the label file is derived from file_name (from JSON).\n",
        "            # If I change the image name on disk, I should also change the label filename.\n",
        "            # Let's use the found src filename as the basis for dest filename to ensure consistency.\n",
        "\n",
        "            if src_path.exists():\n",
        "                dst_path = output_dir / 'images' / split_name / src_path.name\n",
        "                shutil.copy(src_path, dst_path)\n",
        "                # Update file_name to match the one on disk for label generation\n",
        "                file_name = src_path.name\n",
        "            else:\n",
        "                print(f\"Warning: Image {file_name} not found (tried {src_path}).\")\n",
        "                continue\n",
        "\n",
        "            # Create label file\n",
        "            label_path = output_dir / 'labels' / split_name / f\"{Path(file_name).stem}.txt\"\n",
        "\n",
        "            anns = img_to_anns.get(img_id, [])\n",
        "            with open(label_path, 'w') as f:\n",
        "                for ann in anns:\n",
        "                    if 'segmentation' not in ann:\n",
        "                        continue\n",
        "\n",
        "                    cat_idx = cat_id_to_idx[ann['category_id']]\n",
        "\n",
        "                    for seg in ann['segmentation']:\n",
        "                        # seg is a list of coordinates [x1, y1, x2, y2, ...]\n",
        "                        # Normalize\n",
        "                        points = np.array(seg).reshape(-1, 2).astype(float)\n",
        "                        points[:, 0] /= width\n",
        "                        points[:, 1] /= height\n",
        "\n",
        "                        # Clip to [0, 1] just in case\n",
        "                        points = np.clip(points, 0, 1)\n",
        "\n",
        "                        # Format: class x1 y1 x2 y2 ...\n",
        "                        line = f\"{cat_idx} \" + \" \".join([f\"{x:.6f} {y:.6f}\" for x, y in points])\n",
        "                        f.write(line + \"\\n\")\n",
        "\n",
        "    process_images(train_images, 'train')\n",
        "    process_images(val_images, 'val')\n",
        "\n",
        "    # Create data.yaml\n",
        "    yaml_content = f\"\"\"\n",
        "path: {output_dir.absolute()}\n",
        "train: images/train\n",
        "val: images/val\n",
        "names:\n",
        "\"\"\"\n",
        "    for idx, name in enumerate(cat_names):\n",
        "        yaml_content += f\"  {idx}: {name}\\n\"\n",
        "\n",
        "    with open(output_dir / 'data.yaml', 'w') as f:\n",
        "        f.write(yaml_content)\n",
        "\n",
        "    print(f\"Dataset prepared at {output_dir}\")\n",
        "    print(f\"data.yaml created at {output_dir / 'data.yaml'}\")\n",
        "\n",
        "convert_coco_to_yolo(\n",
        "    json_path=f'{DATA_DIR}/annotations.coco.json',\n",
        "    source_img_dir=DATA_DIR,\n",
        "    output_dir='datasets/contrail-seg'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0nH5qVflAp8",
        "outputId": "b09cc4fd-ab74-4d02-fe77-01a48f622a04"
      },
      "id": "M0nH5qVflAp8",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categories mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}\n",
            "Category names: ['contrail', 'contrail maybe', 'contrail old', 'contrail veryold', 'contrail young', 'parasite', 'sun', 'unknow']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1280/1280 [00:23<00:00, 54.49it/s] \n",
            "Processing val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 320/320 [00:00<00:00, 372.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset prepared at datasets/contrail-seg\n",
            "data.yaml created at datasets/contrail-seg/data.yaml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Custom callback to log metrics to W&B\n"
      ],
      "metadata": {
        "id": "i68kYcygphtC"
      },
      "id": "i68kYcygphtC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "89e6dea4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "89e6dea4",
        "outputId": "4f3358c9-9f65-465b-81d2-3daf27051d60"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251205_222845-tsxu2q9l</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shrenikborad-the-george-washington-university/contrails-seg/runs/tsxu2q9l' target=\"_blank\">azure-grass-16</a></strong> to <a href='https://wandb.ai/shrenikborad-the-george-washington-university/contrails-seg' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/shrenikborad-the-george-washington-university/contrails-seg' target=\"_blank\">https://wandb.ai/shrenikborad-the-george-washington-university/contrails-seg</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/shrenikborad-the-george-washington-university/contrails-seg/runs/tsxu2q9l' target=\"_blank\">https://wandb.ai/shrenikborad-the-george-washington-university/contrails-seg/runs/tsxu2q9l</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'RANK' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1527067823.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yolo11l-seg.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0madd_wandb_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_model_checkpointing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m model.train(\n\u001b[1;32m      7\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"/content/datasets/contrail-seg/data.yaml\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/integration/ultralytics/callback.py\u001b[0m in \u001b[0;36madd_wandb_callback\u001b[0;34m(model, epoch_logging_interval, enable_model_checkpointing, enable_train_validation_logging, enable_validation_logging, enable_prediction_logging, max_validation_batches, visualize_skeleton)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0mAn\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0multralytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myolo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYOLO\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mWandBUltralyticsCallback\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \"\"\"\n\u001b[0;32m--> 502\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m         wandb_callback = WandBUltralyticsCallback(\n\u001b[1;32m    504\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RANK' is not defined"
          ]
        }
      ],
      "source": [
        "with wandb.init(project=\"contrails-seg\") as run:\n",
        "    def on_train_epoch_end(trainer):\n",
        "        \"\"\"Callback that runs at the end of each training epoch.\"\"\"\n",
        "        metrics = trainer.metrics\n",
        "        epoch = trainer.epoch\n",
        "\n",
        "        # Log training metrics\n",
        "        log_dict = {\n",
        "            \"epoch\": epoch,\n",
        "        }\n",
        "\n",
        "        # Add box loss metrics\n",
        "        if \"train/box_loss\" in metrics:\n",
        "            log_dict[\"train/box_loss\"] = metrics[\"train/box_loss\"]\n",
        "        if \"train/seg_loss\" in metrics:\n",
        "            log_dict[\"train/seg_loss\"] = metrics[\"train/seg_loss\"]\n",
        "        if \"train/cls_loss\" in metrics:\n",
        "            log_dict[\"train/cls_loss\"] = metrics[\"train/cls_loss\"]\n",
        "        if \"train/dfl_loss\" in metrics:\n",
        "            log_dict[\"train/dfl_loss\"] = metrics[\"train/dfl_loss\"]\n",
        "\n",
        "        # Add validation metrics if available\n",
        "        if \"metrics/precision(M)\" in metrics:\n",
        "            log_dict[\"val/precision\"] = metrics[\"metrics/precision(M)\"]\n",
        "        if \"metrics/recall(M)\" in metrics:\n",
        "            log_dict[\"val/recall\"] = metrics[\"metrics/recall(M)\"]\n",
        "        if \"metrics/mAP50(M)\" in metrics:\n",
        "            log_dict[\"val/mAP50\"] = metrics[\"metrics/mAP50(M)\"]\n",
        "        if \"metrics/mAP50-95(M)\" in metrics:\n",
        "            log_dict[\"val/mAP50-95\"] = metrics[\"metrics/mAP50-95(M)\"]\n",
        "\n",
        "        # Log to W&B\n",
        "        run.log(log_dict)\n",
        "    def on_val_end(trainer):\n",
        "        \"\"\"Callback that runs at the end of validation.\"\"\"\n",
        "        validator = trainer.validator\n",
        "        metrics = validator.metrics\n",
        "\n",
        "        # Additional validation metrics can be logged here\n",
        "        val_log_dict = {}\n",
        "\n",
        "        if hasattr(metrics, 'box'):\n",
        "            if hasattr(metrics.box, 'map'):\n",
        "                val_log_dict[\"val/box_mAP\"] = metrics.box.map\n",
        "            if hasattr(metrics.box, 'map50'):\n",
        "                val_log_dict[\"val/box_mAP50\"] = metrics.box.map50\n",
        "\n",
        "        if hasattr(metrics, 'seg'):\n",
        "            if hasattr(metrics.seg, 'map'):\n",
        "                val_log_dict[\"val/seg_mAP\"] = metrics.seg.map\n",
        "            if hasattr(metrics.seg, 'map50'):\n",
        "                val_log_dict[\"val/seg_mAP50\"] = metrics.seg.map50\n",
        "\n",
        "        if val_log_dict:\n",
        "            run.log(val_log_dict)\n",
        "    model = YOLO(\"yolo11l-seg.pt\")\n",
        "    model.add_callback(\"on_train_epoch_end\", on_train_epoch_end)\n",
        "    model.add_callback(\"on_val_end\", on_val_end)\n",
        "    model.train(\n",
        "        data=f\"/content/datasets/contrail-seg/data.yaml\",\n",
        "        epochs=100,\n",
        "        imgsz=640,\n",
        "        name=\"contrail-segmentation-runL\",\n",
        "        exist_ok=True,\n",
        "        batch=-1,\n",
        "        save_period=5,\n",
        "        project=\"/content/drive/MyDrive/contrails_seg/train2\",\n",
        "\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r6kO_I02mkyN"
      },
      "id": "r6kO_I02mkyN",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}